{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetaPop: Metagenomic Population Diversity Analysis\n",
    "\n",
    "This notebook provides an interactive interface for running MetaPop on Google Colab.\n",
    "\n",
    "**MetaPop** analyzes:\n",
    "- **Macrodiversity**: Sample-level diversity (richness, Shannon's H, Simpson, etc.)\n",
    "- **Microdiversity**: Within-population genetic variation (pi, theta, Tajima's D, pN/pS)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "Run this cell first to install all required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install system dependencies (samtools, bcftools, prodigal)\n",
    "!apt-get update -qq 2>/dev/null\n",
    "!apt-get install -y -qq samtools bcftools prodigal 2>/dev/null\n",
    "\n",
    "# Step 2: Install Python dependencies\n",
    "!pip install -q numpy pandas scipy pysam matplotlib seaborn scikit-learn plotly ipywidgets\n",
    "\n",
    "# Step 3: Clone and install MetaPop\n",
    "import os\n",
    "if not os.path.exists('metapop'):\n",
    "    !git clone https://github.com/espickle1/metapop.git\n",
    "\n",
    "%cd metapop\n",
    "!pip install -q .\n",
    "%cd ..\n",
    "\n",
    "print(\"Base dependencies and MetaPop installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 2. Mount Google Drive\n",
    "\n",
    "Mount your Google Drive to access data files and save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Your files will be available at /content/drive/MyDrive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Process BAM files from Google Drive to local Colab storage\nimport shutil\nimport os\n\n# Define paths\ndrive_bam_dir = '/content/drive/MyDrive/metapop_data/bams'  # Your Drive path\nlocal_bam_dir = '/content/local_bams'  # Local Colab storage\n\n# Create local directory\nos.makedirs(local_bam_dir, exist_ok=True)\n\n# Copy all BAM files to local storage\nprint(\"Copying BAM files to local storage (this may take a while)...\")\nfor f in os.listdir(drive_bam_dir):\n    if f.endswith('.bam') or f.endswith('.bai') or f.endswith('.bam.bai'):\n        src = os.path.join(drive_bam_dir, f)\n        dst = os.path.join(local_bam_dir, f)\n        if not os.path.exists(dst):\n            print(f\"  Copying {f}...\")\n            shutil.copy2(src, dst)\n        else:\n            print(f\"  {f} already exists locally\")\n\n# Index BAM files if index doesn't exist\nprint(\"\\nChecking/creating BAM indexes...\")\nfor f in os.listdir(local_bam_dir):\n    if f.endswith('.bam'):\n        bam_path = os.path.join(local_bam_dir, f)\n        bai_path = bam_path + '.bai'\n        alt_bai_path = bam_path[:-4] + '.bai'  # file.bai instead of file.bam.bai\n        if not os.path.exists(bai_path) and not os.path.exists(alt_bai_path):\n            print(f\"  Indexing {f}...\")\n            os.system(f'samtools index \"{bam_path}\"')\n        else:\n            print(f\"  {f} already indexed\")\n\nprint(f\"\\nDone! Use '{local_bam_dir}' as your BAM Directory in the widget above.\")\n\n# Verify BAM files are readable\nprint(\"\\nVerifying BAM files...\")\n!ls -la {local_bam_dir}/*.bam* | head -10"
  },
  {
   "cell_type": "code",
   "source": "# Download files from shared Google Drive links\n!pip install -q gdown\nimport os\nimport re\nimport ipywidgets as widgets\nfrom IPython.display import display, HTML\n\n# --- Input widgets ---\ndisplay(HTML('''\n<style>\n.drive-input textarea, .drive-input input {\n    color: #000 !important; font-family: monospace; font-size: 13px;\n}\n</style>\n'''))\n\nprint(\"=== Download Files from Google Drive Links ===\")\nprint(\"Paste shared Google Drive links below, then click 'Download All'.\")\nprint(\"Link format: https://drive.google.com/file/d/FILE_ID/view?...\")\nprint()\n\nbam_links = widgets.Textarea(\n    value='',\n    placeholder='Paste one Google Drive link per line, e.g.:\\n'\n                'https://drive.google.com/file/d/ABC123.../view?usp=drive_link\\n'\n                'https://drive.google.com/file/d/DEF456.../view?usp=drive_link',\n    description='BAM files:',\n    style={'description_width': '120px'},\n    layout=widgets.Layout(width='95%', height='120px')\n)\nbam_links.add_class('drive-input')\n\nref_link = widgets.Text(\n    value='',\n    placeholder='https://drive.google.com/file/d/FILE_ID/view?usp=drive_link',\n    description='Reference FASTA:',\n    style={'description_width': '120px'},\n    layout=widgets.Layout(width='95%')\n)\nref_link.add_class('drive-input')\n\ndownload_output = widgets.Output(layout={'border': '1px solid #ccc',\n                                         'min_height': '60px',\n                                         'max_height': '400px',\n                                         'overflow_y': 'auto',\n                                         'padding': '8px'})\n\ndef extract_file_id(url):\n    \"\"\"Extract Google Drive file ID from a shared link.\"\"\"\n    url = url.strip()\n    # Match /d/FILE_ID/ or id=FILE_ID\n    m = re.search(r'/d/([a-zA-Z0-9_-]+)', url)\n    if m:\n        return m.group(1)\n    m = re.search(r'id=([a-zA-Z0-9_-]+)', url)\n    if m:\n        return m.group(1)\n    return None\n\ndef download_files(btn):\n    \"\"\"Download all files from the provided links.\"\"\"\n    btn.disabled = True\n    btn.description = 'Downloading...'\n    download_output.clear_output()\n\n    with download_output:\n        bam_dir = '/content/local_bams'\n        ref_dir = '/content/local_refs'\n        os.makedirs(bam_dir, exist_ok=True)\n        os.makedirs(ref_dir, exist_ok=True)\n\n        # --- Download BAM files ---\n        bam_lines = [l.strip() for l in bam_links.value.strip().split('\\n') if l.strip()]\n        if bam_lines:\n            print(f\"{'='*50}\")\n            print(f\"Downloading {len(bam_lines)} BAM file(s)...\")\n            print(f\"{'='*50}\")\n            for i, link in enumerate(bam_lines, 1):\n                fid = extract_file_id(link)\n                if not fid:\n                    print(f\"\\n  [{i}] Could not extract file ID from: {link[:80]}\")\n                    continue\n                # gdown will detect the filename from Drive\n                print(f\"\\n  [{i}] File ID: {fid}\")\n                dl_url = f\"https://drive.google.com/uc?id={fid}\"\n                ret = os.system(f'gdown \"{dl_url}\" -O /tmp/gdown_temp 2>&1')\n                if ret == 0 and os.path.exists('/tmp/gdown_temp'):\n                    # Try to get the real filename from gdown\n                    # Re-download with --fuzzy to get filename\n                    os.remove('/tmp/gdown_temp')\n                    ret = os.system(f'cd \"{bam_dir}\" && gdown \"{dl_url}\" 2>&1')\n                    if ret == 0:\n                        print(f\"      Saved to {bam_dir}/\")\n                    else:\n                        print(f\"      Download failed (exit code {ret})\")\n                else:\n                    # Try direct with --fuzzy flag\n                    ret = os.system(f'cd \"{bam_dir}\" && gdown --fuzzy \"{link}\" 2>&1')\n                    if ret == 0:\n                        print(f\"      Saved to {bam_dir}/\")\n                    else:\n                        print(f\"      Download failed\")\n        else:\n            print(\"No BAM links provided (skipping).\")\n\n        # --- Download reference FASTA ---\n        ref_url = ref_link.value.strip()\n        if ref_url:\n            print(f\"\\n{'='*50}\")\n            print(\"Downloading reference FASTA...\")\n            print(f\"{'='*50}\")\n            fid = extract_file_id(ref_url)\n            if fid:\n                ret = os.system(\n                    f'cd \"{ref_dir}\" && gdown \"https://drive.google.com/uc?id={fid}\" 2>&1'\n                )\n                if ret == 0:\n                    # Check what was downloaded\n                    files = os.listdir(ref_dir)\n                    for fn in files:\n                        fpath = os.path.join(ref_dir, fn)\n                        fsize = os.path.getsize(fpath)\n                        print(f\"  Saved: {fn} ({fsize:,} bytes)\")\n                        # Sanity check\n                        with open(fpath, 'rb') as f:\n                            first_bytes = f.read(4)\n                        if first_bytes[:1] == b'>':\n                            print(f\"  Valid FASTA detected\")\n                        elif first_bytes[:2] == b'\\x1f\\x8b':\n                            print(f\"  Gzip-compressed file detected\")\n                        else:\n                            print(f\"  WARNING: doesn't look like FASTA \"\n                                  f\"(starts with: {first_bytes})\")\n                else:\n                    print(f\"  Download failed\")\n            else:\n                print(f\"  Could not extract file ID from: {ref_url[:80]}\")\n        else:\n            print(\"\\nNo reference link provided (skipping).\")\n\n        # --- Summary ---\n        print(f\"\\n{'='*50}\")\n        print(\"DOWNLOAD SUMMARY\")\n        print(f\"{'='*50}\")\n        if os.path.exists(bam_dir):\n            bams = [f for f in os.listdir(bam_dir) if f.endswith('.bam')]\n            print(f\"  BAM files in {bam_dir}: {len(bams)}\")\n            for b in sorted(bams):\n                print(f\"    - {b}\")\n        if os.path.exists(ref_dir):\n            refs = os.listdir(ref_dir)\n            print(f\"  Reference files in {ref_dir}: {len(refs)}\")\n            for r in sorted(refs):\n                print(f\"    - {r}\")\n\n    btn.disabled = False\n    btn.description = 'Download All'\n\n# --- Layout ---\ndl_button = widgets.Button(\n    description='Download All',\n    button_style='primary',\n    icon='download',\n    layout=widgets.Layout(width='180px', height='36px')\n)\ndl_button.on_click(download_files)\n\ndisplay(widgets.VBox([\n    widgets.HTML('<b>BAM Files</b> (one link per line):'),\n    bam_links,\n    widgets.HTML('<br><b>Reference FASTA</b> (single link):'),\n    ref_link,\n    widgets.HTML('<br>'),\n    dl_button,\n    widgets.HTML('<br><b>Download Progress:</b>'),\n    download_output\n]))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Validate BAM Files & References\n\nRun this cell to check for common issues **before** running MetaPop:\n1. **Integrity check** — verifies BAM files aren't corrupted\n2. **Re-indexing** — creates fresh `.bai` index files (eliminates stale index issues)\n3. **Header vs reference comparison** — checks that contig names in your BAM headers match your reference FASTAs\n\nIf you see **\"ZERO contig names match\"**, that means the BAM files were aligned against different reference sequences than the FASTAs you're providing. You'll need the exact reference used during alignment.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# === BAM File Validation & Diagnostics ===\n# This cell checks for common issues that cause MetaPop to produce empty results.\n\nimport os\nimport subprocess\nimport gzip\n\n# --- Configuration ---\n# These should match the paths used in the cells above\nbam_dir = '/content/local_bams'\nref_dir = '/content/local_refs'\n\n# -------------------------------------------------------\n# 1. BAM INTEGRITY CHECK\n# -------------------------------------------------------\nprint(\"=\" * 60)\nprint(\"1. BAM INTEGRITY CHECK (samtools quickcheck)\")\nprint(\"=\" * 60)\n\nbam_files = sorted([f for f in os.listdir(bam_dir) if f.endswith('.bam')])\nprint(f\"Found {len(bam_files)} BAM file(s)\\n\")\n\nfor f in bam_files:\n    bam_path = os.path.join(bam_dir, f)\n    ret = subprocess.run(['samtools', 'quickcheck', bam_path],\n                         capture_output=True, text=True)\n    status = \"PASS\" if ret.returncode == 0 else \"FAIL\"\n    print(f\"  [{status}] {f}\")\n    if ret.returncode != 0:\n        print(f\"         Error: {ret.stderr.strip()}\")\n\n# -------------------------------------------------------\n# 1b. CHECK FOR NAMING ISSUES\n# -------------------------------------------------------\nprint(f\"\\n{'=' * 60}\")\nprint(\"1b. BAM FILE NAMING CHECK\")\nprint(\"=\" * 60)\n\nhas_naming_issues = False\nfor f in bam_files:\n    issues = []\n    if f.startswith('Copy of '):\n        issues.append(\"starts with 'Copy of ' (Google Drive duplicate)\")\n    if ' ' in f:\n        issues.append(\"contains spaces\")\n    if issues:\n        has_naming_issues = True\n        print(f\"  WARNING: {f}\")\n        for issue in issues:\n            print(f\"           -> {issue}\")\n\nif has_naming_issues:\n    print(\"\\n  Renaming BAM files to clean names...\")\n    new_bam_files = []\n    for f in bam_files:\n        old_path = os.path.join(bam_dir, f)\n        clean_name = f\n        if clean_name.startswith('Copy of '):\n            clean_name = clean_name[len('Copy of '):]\n        clean_name = clean_name.replace(' ', '_')\n        new_path = os.path.join(bam_dir, clean_name)\n        if old_path != new_path:\n            # Also rename the index file\n            for idx_ext in ['.bai']:\n                old_idx = old_path + idx_ext\n                new_idx = new_path + idx_ext\n                if os.path.exists(old_idx):\n                    os.rename(old_idx, new_idx)\n            os.rename(old_path, new_path)\n            print(f\"    {f}  ->  {clean_name}\")\n        new_bam_files.append(clean_name)\n    bam_files = new_bam_files\n    print(\"  Done! Files renamed.\")\nelse:\n    print(\"  All filenames look clean.\")\n\n# -------------------------------------------------------\n# 2. RE-INDEX ALL BAM FILES (fresh .bai files)\n# -------------------------------------------------------\nprint(f\"\\n{'=' * 60}\")\nprint(\"2. RE-INDEXING ALL BAM FILES (fresh .bai files)\")\nprint(\"=\" * 60)\n\nfor f in bam_files:\n    bam_path = os.path.join(bam_dir, f)\n\n    # Remove old indexes\n    for idx_path in [bam_path + '.bai', bam_path.replace('.bam', '.bai')]:\n        if os.path.exists(idx_path):\n            os.remove(idx_path)\n\n    # Check if coordinate-sorted\n    ret = subprocess.run(['samtools', 'view', '-H', bam_path],\n                         capture_output=True, text=True)\n    if 'SO:coordinate' not in ret.stdout:\n        print(f\"  WARNING: {f} not coordinate-sorted — sorting now...\")\n        sorted_path = bam_path + '.sorting.tmp.bam'\n        subprocess.run(['samtools', 'sort', '-o', sorted_path, bam_path])\n        os.replace(sorted_path, bam_path)\n\n    # Create fresh index\n    ret = subprocess.run(['samtools', 'index', bam_path],\n                         capture_output=True, text=True)\n    if ret.returncode == 0:\n        print(f\"  Indexed: {f}\")\n    else:\n        print(f\"  FAILED:  {f} — {ret.stderr.strip()}\")\n\n# -------------------------------------------------------\n# 3. EXTRACT CONTIG NAMES FROM BAM HEADERS\n# -------------------------------------------------------\nprint(f\"\\n{'=' * 60}\")\nprint(\"3. BAM HEADER vs REFERENCE FASTA COMPARISON\")\nprint(\"=\" * 60)\n\nall_bam_contigs = set()\n\nfor f in bam_files:\n    bam_path = os.path.join(bam_dir, f)\n    ret = subprocess.run(['samtools', 'view', '-H', bam_path],\n                         capture_output=True, text=True)\n    contigs = set()\n    for line in ret.stdout.split('\\n'):\n        if line.startswith('@SQ'):\n            for part in line.split('\\t'):\n                if part.startswith('SN:'):\n                    contigs.add(part[3:])\n    all_bam_contigs.update(contigs)\n    print(f\"\\n  {f}: {len(contigs)} reference contig(s) in header\")\n    for c in sorted(contigs)[:5]:\n        print(f\"    - {c}\")\n    if len(contigs) > 5:\n        print(f\"    ... and {len(contigs) - 5} more\")\n\n# -------------------------------------------------------\n# 4. EXTRACT CONTIG NAMES FROM REFERENCE FASTAs\n# -------------------------------------------------------\nref_contigs = set()\n\ndef is_gzipped(filepath):\n    \"\"\"Check if a file is gzip-compressed by reading magic bytes.\"\"\"\n    with open(filepath, 'rb') as f:\n        return f.read(2) == b'\\x1f\\x8b'\n\nif os.path.exists(ref_dir):\n    ref_files = sorted([f for f in os.listdir(ref_dir)\n                        if f.endswith(('.fa', '.fasta', '.fna',\n                                       '.fa.gz', '.fasta.gz', '.fna.gz'))])\n    print(f\"\\nReference directory: {len(ref_files)} FASTA file(s)\")\n\n    if len(ref_files) == 0:\n        # Maybe files have unusual extensions — list everything\n        all_files = os.listdir(ref_dir)\n        print(f\"  No standard FASTA files found. All files in directory:\")\n        for af in sorted(all_files):\n            fpath = os.path.join(ref_dir, af)\n            fsize = os.path.getsize(fpath)\n            gz = \" [gzip-compressed]\" if is_gzipped(fpath) else \"\"\n            print(f\"    {af} ({fsize:,} bytes){gz}\")\n\n    for f in ref_files:\n        ref_path = os.path.join(ref_dir, f)\n        file_contigs = set()\n\n        # Auto-detect gzip compression\n        compressed = is_gzipped(ref_path)\n        opener = gzip.open if compressed else open\n        mode = 'rt' if compressed else 'r'\n\n        if compressed:\n            print(f\"  {f}: [gzip-compressed] \", end=\"\")\n\n        try:\n            with opener(ref_path, mode) as fh:\n                for line in fh:\n                    if line.startswith('>'):\n                        first_word = line[1:].strip().split()[0]\n                        file_contigs.add(first_word)\n        except Exception as e:\n            print(f\"  ERROR reading {f}: {e}\")\n            # Try binary sniff to identify file type\n            with open(ref_path, 'rb') as bf:\n                magic = bf.read(4)\n            print(f\"    File magic bytes: {magic.hex()} ({magic})\")\n            continue\n\n        ref_contigs.update(file_contigs)\n        print(f\"  {f}: {len(file_contigs)} contig(s)\")\n        for c in sorted(file_contigs)[:3]:\n            print(f\"    - {c}\")\n        if len(file_contigs) > 3:\n            print(f\"    ... and {len(file_contigs) - 3} more\")\nelse:\n    print(f\"\\n  WARNING: Reference directory not found: {ref_dir}\")\n    print(f\"  Make sure you ran the download cell above first.\")\n\n# -------------------------------------------------------\n# 5. DIAGNOSIS\n# -------------------------------------------------------\nprint(f\"\\n{'=' * 60}\")\nprint(\"DIAGNOSIS\")\nprint(\"=\" * 60)\n\nif all_bam_contigs and ref_contigs:\n    overlap = all_bam_contigs & ref_contigs\n    only_in_bam = all_bam_contigs - ref_contigs\n    only_in_ref = ref_contigs - all_bam_contigs\n\n    print(f\"\\n  Unique contigs in BAM headers:  {len(all_bam_contigs)}\")\n    print(f\"  Unique contigs in references:   {len(ref_contigs)}\")\n    print(f\"  Matching contigs:               {len(overlap)}\")\n\n    if len(overlap) == 0:\n        print(\"\\n  *** PROBLEM: ZERO contig names match! ***\")\n        print(\"  This is why MetaPop produces empty results.\")\n        print(\"\\n  Example BAM contig names:\")\n        for c in sorted(all_bam_contigs)[:5]:\n            print(f\"    BAM: '{c}'\")\n        print(\"  Example reference contig names:\")\n        for c in sorted(ref_contigs)[:5]:\n            print(f\"    REF: '{c}'\")\n        print(\"\\n  The BAM files were aligned against different references\")\n        print(\"  than the FASTA files you are providing to MetaPop.\")\n        print(\"  You need the EXACT reference FASTA used during alignment.\")\n    elif len(overlap) < len(all_bam_contigs):\n        pct = 100 * len(overlap) / len(all_bam_contigs)\n        print(f\"\\n  Partial match: {pct:.1f}% of BAM contigs found in references\")\n        print(f\"  {len(only_in_bam)} BAM contig(s) NOT in references:\")\n        for c in sorted(only_in_bam)[:5]:\n            print(f\"    Missing: '{c}'\")\n    else:\n        print(\"\\n  All BAM contigs found in reference files!\")\n        print(\"  Header/reference mismatch is NOT the problem.\")\n        print(\"  Check MetaPop filter settings (coverage, depth thresholds).\")\nelif not all_bam_contigs:\n    print(\"\\n  No contigs found in BAM headers — files may be empty/unmapped.\")\nelif not ref_contigs:\n    print(\"\\n  No reference FASTAs found — cannot compare.\")\n\nprint(f\"\\n{'=' * 60}\")\nprint(\"VALIDATION COMPLETE\")\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Import Libraries and Initialize"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Try to import plotly for interactive plots\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    PLOTLY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n",
    "print(f\"Interactive plots (Plotly): {'Available' if PLOTLY_AVAILABLE else 'Not available'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Configure Pipeline Parameters\n\nUse the interactive widgets below to configure your analysis parameters."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# File path inputs with live validation and dark text\nimport ipywidgets as widgets\nfrom IPython.display import display, HTML\n\n# Add CSS to make widget text darker and more readable\ndisplay(HTML('''\n<style>\n.jupyter-widgets .widget-text input {\n    color: #000000 !important;\n    font-weight: 500;\n}\n.jupyter-widgets .widget-label {\n    color: #000000 !important;\n    font-weight: bold;\n}\n.jupyter-widgets .widget-inline-hbox .widget-label,\n.jupyter-widgets .widget-inline-vbox .widget-label {\n    color: #000000 !important;\n    font-weight: bold;\n}\n</style>\n'''))\n\nprint(\"=== File Paths ===\")\nprint(\"Configure your input/output directories below.\")\nprint()\n\ninput_dir = widgets.Text(\n    value='/content/local_bams',\n    description='BAM Directory:',\n    style={'description_width': '150px', 'description_color': '#000000'},\n    layout=widgets.Layout(width='90%'),\n    continuous_update=True\n)\n\nreference = widgets.Text(\n    value='/content/local_refs',\n    description='Reference Directory:',\n    placeholder='Directory containing reference FASTA files',\n    style={'description_width': '150px', 'description_color': '#000000'},\n    layout=widgets.Layout(width='90%'),\n    continuous_update=True\n)\n\ngenes = widgets.Text(\n    value='',\n    description='Genes File (optional):',\n    placeholder='Leave empty to auto-generate with Prodigal',\n    style={'description_width': '150px', 'description_color': '#000000'},\n    layout=widgets.Layout(width='90%'),\n    continuous_update=True\n)\n\nnorm_file = widgets.Text(\n    value='',\n    description='Normalization File:',\n    placeholder='Leave empty to auto-generate from BAM read counts',\n    style={'description_width': '150px', 'description_color': '#000000'},\n    layout=widgets.Layout(width='90%'),\n    continuous_update=True\n)\n\noutput_dir = widgets.Text(\n    value='/content/drive/MyDrive/metapop_results',\n    description='Output Directory:',\n    style={'description_width': '150px', 'description_color': '#000000'},\n    layout=widgets.Layout(width='90%'),\n    continuous_update=True\n)\n\n# Status indicator for path validation\npath_status = widgets.HTML(value='')\n\ndef validate_paths(change=None):\n    \"\"\"Validate paths and update status.\"\"\"\n    status_parts = []\n    \n    # Check BAM directory\n    if os.path.exists(input_dir.value):\n        bam_files = [f for f in os.listdir(input_dir.value) if f.endswith('.bam')]\n        status_parts.append(f\"✅ BAM directory: {len(bam_files)} BAM file(s) found\")\n    else:\n        status_parts.append(f\"❌ BAM directory not found\")\n    \n    # Check reference directory\n    if os.path.exists(reference.value):\n        if os.path.isdir(reference.value):\n            ref_files = [f for f in os.listdir(reference.value) \n                        if f.endswith(('.fa', '.fasta', '.fna'))]\n            status_parts.append(f\"✅ Reference directory: {len(ref_files)} FASTA file(s) found\")\n        else:\n            status_parts.append(f\"⚠️ Reference is a file, not directory\")\n    else:\n        status_parts.append(f\"❌ Reference directory not found\")\n    \n    # Check output directory\n    if os.path.exists(output_dir.value):\n        status_parts.append(f\"✅ Output directory exists\")\n    else:\n        status_parts.append(f\"ℹ️ Output directory will be created\")\n    \n    path_status.value = '<br>'.join(status_parts)\n\n# Connect validation to path changes\ninput_dir.observe(validate_paths, names='value')\nreference.observe(validate_paths, names='value')\noutput_dir.observe(validate_paths, names='value')\n\n# Initial validation\nvalidate_paths()\n\n# Display widgets\ndisplay(widgets.VBox([\n    input_dir,\n    reference, \n    genes,\n    norm_file,\n    output_dir,\n    widgets.HTML('<hr style=\"margin: 10px 0;\">'),\n    widgets.HTML('<b>Path Status:</b>'),\n    path_status\n]))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter parameters with live value display and dark text\n",
    "print(\"=== Filter Parameters ===\")\n",
    "print(\"Adjust the sliders below. Values update in real-time.\")\n",
    "print()\n",
    "\n",
    "min_pct_id = widgets.FloatSlider(\n",
    "    value=95.0, min=80.0, max=100.0, step=0.5,\n",
    "    description='Min % Identity:',\n",
    "    style={'description_width': '150px', 'description_color': '#000000'},\n",
    "    layout=widgets.Layout(width='70%'),\n",
    "    readout=True,\n",
    "    readout_format='.1f',\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "min_length = widgets.IntSlider(\n",
    "    value=50, min=25, max=200, step=5,\n",
    "    description='Min Read Length:',\n",
    "    style={'description_width': '150px', 'description_color': '#000000'},\n",
    "    layout=widgets.Layout(width='70%'),\n",
    "    readout=True,\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "min_cov = widgets.IntSlider(\n",
    "    value=20, min=0, max=100, step=5,\n",
    "    description='Min Coverage (%):',\n",
    "    style={'description_width': '150px', 'description_color': '#000000'},\n",
    "    layout=widgets.Layout(width='70%'),\n",
    "    readout=True,\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "min_dep = widgets.IntSlider(\n",
    "    value=10, min=1, max=100, step=1,\n",
    "    description='Min Depth:',\n",
    "    style={'description_width': '150px', 'description_color': '#000000'},\n",
    "    layout=widgets.Layout(width='70%'),\n",
    "    readout=True,\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "truncation = widgets.FloatSlider(\n",
    "    value=10.0, min=0.0, max=49.0, step=1.0,\n",
    "    description='Truncation (%):',\n",
    "    style={'description_width': '150px', 'description_color': '#000000'},\n",
    "    layout=widgets.Layout(width='70%'),\n",
    "    readout=True,\n",
    "    readout_format='.1f',\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "# Live summary of filter settings\n",
    "filter_summary = widgets.HTML(value='')\n",
    "\n",
    "def update_filter_summary(change=None):\n",
    "    \"\"\"Update the filter summary display.\"\"\"\n",
    "    summary = f\"\"\"\n",
    "    <div style=\"background-color: #f0f0f0; padding: 10px; border-radius: 5px; margin-top: 10px; color: #000000;\">\n",
    "    <b>Current Filter Settings:</b><br>\n",
    "    • Reads must have ≥{min_pct_id.value:.1f}% identity to reference<br>\n",
    "    • Reads must be ≥{min_length.value} bp long<br>\n",
    "    • Contigs need ≥{min_cov.value}% coverage breadth<br>\n",
    "    • Positions need ≥{min_dep.value}x read depth<br>\n",
    "    • Truncate {truncation.value:.0f}% from each contig end\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    filter_summary.value = summary\n",
    "\n",
    "# Connect summary update to all sliders\n",
    "for slider in [min_pct_id, min_length, min_cov, min_dep, truncation]:\n",
    "    slider.observe(update_filter_summary, names='value')\n",
    "\n",
    "# Initial summary\n",
    "update_filter_summary()\n",
    "\n",
    "# Display with organized layout\n",
    "display(widgets.VBox([\n",
    "    min_pct_id,\n",
    "    min_length,\n",
    "    min_cov,\n",
    "    min_dep,\n",
    "    truncation,\n",
    "    filter_summary\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis options with live summary and dark text\n",
    "print(\"=== Analysis Options ===\")\n",
    "print(\"Select which analyses to run and configure threads.\")\n",
    "print()\n",
    "\n",
    "run_preproc = widgets.Checkbox(\n",
    "    value=True, \n",
    "    description='Run Preprocessing',\n",
    "    style={'description_width': 'initial', 'description_color': '#000000'},\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "run_microdiv = widgets.Checkbox(\n",
    "    value=True, \n",
    "    description='Run Microdiversity Analysis',\n",
    "    style={'description_width': 'initial', 'description_color': '#000000'},\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "run_macrodiv = widgets.Checkbox(\n",
    "    value=True, \n",
    "    description='Run Macrodiversity Analysis',\n",
    "    style={'description_width': 'initial', 'description_color': '#000000'},\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "run_viz = widgets.Checkbox(\n",
    "    value=True, \n",
    "    description='Generate Visualizations',\n",
    "    style={'description_width': 'initial', 'description_color': '#000000'},\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "threads = widgets.IntSlider(\n",
    "    value=4, min=1, max=16, step=1,\n",
    "    description='Threads:',\n",
    "    style={'description_width': '150px', 'description_color': '#000000'},\n",
    "    layout=widgets.Layout(width='50%'),\n",
    "    readout=True,\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "# Live summary of what will run\n",
    "analysis_summary = widgets.HTML(value='')\n",
    "\n",
    "def update_analysis_summary(change=None):\n",
    "    \"\"\"Update the analysis summary.\"\"\"\n",
    "    analyses = []\n",
    "    if run_preproc.value:\n",
    "        analyses.append(\"✅ Preprocessing (filter reads, compute coverage)\")\n",
    "    else:\n",
    "        analyses.append(\"⏭️ Skip preprocessing\")\n",
    "    \n",
    "    if run_microdiv.value:\n",
    "        analyses.append(\"✅ Microdiversity (SNPs, pi, theta, Tajima's D, pN/pS)\")\n",
    "    else:\n",
    "        analyses.append(\"⏭️ Skip microdiversity\")\n",
    "    \n",
    "    if run_macrodiv.value:\n",
    "        analyses.append(\"✅ Macrodiversity (richness, Shannon's H, beta diversity)\")\n",
    "    else:\n",
    "        analyses.append(\"⏭️ Skip macrodiversity\")\n",
    "    \n",
    "    if run_viz.value:\n",
    "        analyses.append(\"✅ Visualizations (plots and figures)\")\n",
    "    else:\n",
    "        analyses.append(\"⏭️ Skip visualizations\")\n",
    "    \n",
    "    summary = f\"\"\"\n",
    "    <div style=\"background-color: #e8f4e8; padding: 10px; border-radius: 5px; margin-top: 10px; color: #000000;\">\n",
    "    <b>Pipeline Configuration:</b><br>\n",
    "    {'<br>'.join(analyses)}<br>\n",
    "    <br>\n",
    "    <b>Using {threads.value} thread(s)</b> for parallel processing\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    analysis_summary.value = summary\n",
    "\n",
    "# Connect to all checkboxes and threads\n",
    "for widget in [run_preproc, run_microdiv, run_macrodiv, run_viz, threads]:\n",
    "    widget.observe(update_analysis_summary, names='value')\n",
    "\n",
    "# Initial summary\n",
    "update_analysis_summary()\n",
    "\n",
    "# Organize checkboxes in columns\n",
    "checkbox_box = widgets.HBox([\n",
    "    widgets.VBox([run_preproc, run_microdiv]),\n",
    "    widgets.VBox([run_macrodiv, run_viz])\n",
    "])\n",
    "\n",
    "display(widgets.VBox([\n",
    "    checkbox_box,\n",
    "    widgets.HTML('<br>'),\n",
    "    threads,\n",
    "    analysis_summary\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Run MetaPop Pipeline"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import subprocess\nimport time\nimport ipywidgets as widgets\nfrom IPython.display import display, HTML\n\n# --- Confirmation summary (updates live as you change widgets above) ---\nconfirm_html = widgets.HTML()\n\ndef update_confirmation(change=None):\n    \"\"\"Build a live summary of all current settings.\"\"\"\n    analyses = []\n    if run_preproc.value:  analyses.append(\"Preprocessing\")\n    if run_microdiv.value: analyses.append(\"Microdiversity\")\n    if run_macrodiv.value: analyses.append(\"Macrodiversity\")\n    if run_viz.value:      analyses.append(\"Visualizations\")\n\n    confirm_html.value = f\"\"\"\n    <div style=\"background:#fffde7; border:2px solid #f9a825; border-radius:8px;\n                padding:14px; margin:10px 0; color:#000;\">\n      <h3 style=\"margin-top:0; color:#e65100;\">Review Settings Before Running</h3>\n      <table style=\"color:#000; font-size:14px; border-collapse:collapse;\">\n        <tr><td style=\"padding:3px 12px 3px 0;\"><b>BAM Directory:</b></td>\n            <td><code>{input_dir.value}</code></td></tr>\n        <tr><td style=\"padding:3px 12px 3px 0;\"><b>Reference Dir:</b></td>\n            <td><code>{reference.value}</code></td></tr>\n        <tr><td style=\"padding:3px 12px 3px 0;\"><b>Genes File:</b></td>\n            <td><code>{genes.value or '(auto-generate with Prodigal)'}</code></td></tr>\n        <tr><td style=\"padding:3px 12px 3px 0;\"><b>Norm File:</b></td>\n            <td><code>{norm_file.value or '(auto-generate from BAM read counts)'}</code></td></tr>\n        <tr><td style=\"padding:3px 12px 3px 0;\"><b>Output Dir:</b></td>\n            <td><code>{output_dir.value}</code></td></tr>\n        <tr><td colspan=\"2\" style=\"padding:6px 0 3px;\"><hr style=\"margin:0;\"></td></tr>\n        <tr><td style=\"padding:3px 12px 3px 0;\"><b>Min % Identity:</b></td>\n            <td>{min_pct_id.value:.1f}%</td></tr>\n        <tr><td style=\"padding:3px 12px 3px 0;\"><b>Min Read Length:</b></td>\n            <td>{min_length.value} bp</td></tr>\n        <tr><td style=\"padding:3px 12px 3px 0;\"><b>Min Coverage:</b></td>\n            <td>{min_cov.value}%</td></tr>\n        <tr><td style=\"padding:3px 12px 3px 0;\"><b>Min Depth:</b></td>\n            <td>{min_dep.value}x</td></tr>\n        <tr><td style=\"padding:3px 12px 3px 0;\"><b>Truncation:</b></td>\n            <td>{truncation.value:.0f}%</td></tr>\n        <tr><td colspan=\"2\" style=\"padding:6px 0 3px;\"><hr style=\"margin:0;\"></td></tr>\n        <tr><td style=\"padding:3px 12px 3px 0;\"><b>Analyses:</b></td>\n            <td>{', '.join(analyses) if analyses else '<span style=\"color:red;\">None selected!</span>'}</td></tr>\n        <tr><td style=\"padding:3px 12px 3px 0;\"><b>Threads:</b></td>\n            <td>{threads.value}</td></tr>\n      </table>\n    </div>\n    \"\"\"\n\n# Connect all widgets to live-update the confirmation\nfor w in [input_dir, reference, genes, norm_file, output_dir,\n          min_pct_id, min_length, min_cov, min_dep, truncation,\n          run_preproc, run_microdiv, run_macrodiv, run_viz, threads]:\n    w.observe(update_confirmation, names='value')\n\nupdate_confirmation()\n\n# --- Progress output area (separate from button so it doesn't disappear) ---\nprogress_output = widgets.Output(layout={'border': '1px solid #ccc',\n                                         'min_height': '100px',\n                                         'max_height': '500px',\n                                         'overflow_y': 'auto',\n                                         'padding': '8px'})\nstatus_html = widgets.HTML(value='<i>Ready. Click \"Run MetaPop\" to start.</i>')\n\ndef run_metapop(btn):\n    \"\"\"Run the MetaPop pipeline with configured parameters.\"\"\"\n    btn.disabled = True\n    btn.description = 'Running...'\n    btn.icon = 'spinner'\n    progress_output.clear_output()\n    status_html.value = '<b style=\"color:#1565c0;\">Running MetaPop pipeline...</b>'\n\n    with progress_output:\n        # Validate inputs\n        if not os.path.exists(input_dir.value):\n            print(f\"Error: BAM directory not found: {input_dir.value}\")\n            status_html.value = '<b style=\"color:red;\">Error: BAM directory not found</b>'\n            btn.disabled = False\n            btn.description = 'Run MetaPop'\n            btn.icon = 'play'\n            return\n\n        ref_path = reference.value\n        if os.path.isfile(ref_path):\n            print(f\"Note: Reference is a file — using parent directory.\")\n            ref_path = os.path.dirname(ref_path)\n\n        if not os.path.exists(ref_path):\n            print(f\"Error: Reference directory not found: {ref_path}\")\n            status_html.value = '<b style=\"color:red;\">Error: Reference directory not found</b>'\n            btn.disabled = False\n            btn.description = 'Run MetaPop'\n            btn.icon = 'play'\n            return\n\n        os.makedirs(output_dir.value, exist_ok=True)\n\n        # Build command\n        cmd = [\n            'metapop',\n            '--input_samples', input_dir.value,\n            '--reference', ref_path,\n            '--output', output_dir.value,\n            '--id_min', str(min_pct_id.value),\n            '--min_len', str(min_length.value),\n            '--min_cov', str(min_cov.value),\n            '--min_dep', str(min_dep.value),\n            '--trunc', str(truncation.value),\n            '--threads', str(threads.value),\n        ]\n\n        if genes.value:\n            cmd.extend(['--genes', genes.value])\n        if norm_file.value:\n            cmd.extend(['--norm', norm_file.value])\n        if not run_microdiv.value:\n            cmd.append('--no_micro')\n        if not run_macrodiv.value:\n            cmd.append('--no_macro')\n        if not run_viz.value:\n            cmd.append('--no_viz')\n\n        print(f\"Command: {' '.join(cmd)}\")\n        print(\"=\" * 50)\n        start_time = time.time()\n\n        try:\n            process = subprocess.Popen(\n                cmd,\n                stdout=subprocess.PIPE,\n                stderr=subprocess.STDOUT,\n                text=True,\n                bufsize=1\n            )\n\n            for line in process.stdout:\n                print(line, end='')\n\n            process.wait()\n            elapsed = time.time() - start_time\n\n            if process.returncode == 0:\n                print(f\"\\n{'=' * 50}\")\n                print(f\"Pipeline completed in {elapsed:.0f}s\")\n                print(f\"Results saved to: {output_dir.value}\")\n                status_html.value = (\n                    f'<b style=\"color:green;\">Complete!</b> '\n                    f'Finished in {elapsed:.0f}s. Results in <code>{output_dir.value}</code>'\n                )\n            else:\n                print(f\"\\nMetaPop exited with code: {process.returncode}\")\n                status_html.value = (\n                    f'<b style=\"color:red;\">Failed</b> (exit code {process.returncode}). '\n                    f'See output above.'\n                )\n\n        except FileNotFoundError:\n            print(\"Error: MetaPop command not found.\")\n            print(\"Try running: !pip install -e /content/metapop\")\n            status_html.value = '<b style=\"color:red;\">Error: metapop command not found</b>'\n        except Exception as e:\n            print(f\"Error: {e}\")\n            import traceback\n            traceback.print_exc()\n            status_html.value = f'<b style=\"color:red;\">Error: {e}</b>'\n\n    btn.disabled = False\n    btn.description = 'Run MetaPop'\n    btn.icon = 'play'\n\n# --- Layout ---\nrun_button = widgets.Button(\n    description='Run MetaPop',\n    button_style='success',\n    tooltip='Click to start the pipeline with the settings shown above',\n    icon='play',\n    layout=widgets.Layout(width='200px', height='40px')\n)\nrun_button.on_click(run_metapop)\n\ndisplay(widgets.VBox([\n    confirm_html,\n    widgets.HBox([run_button, widgets.HTML('&nbsp;&nbsp;'), status_html]),\n    widgets.HTML('<br><b>Pipeline Output:</b>'),\n    progress_output\n]))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. View Results\n\nAfter the pipeline completes, use the cells below to explore results interactively."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results():\n",
    "    \"\"\"Load and display MetaPop results.\"\"\"\n",
    "    results_path = os.path.join(output_dir.value, 'MetaPop')\n",
    "    \n",
    "    if not os.path.exists(results_path):\n",
    "        print(f\"Results not found at: {results_path}\")\n",
    "        print(\"Please run the pipeline first.\")\n",
    "        return None\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Load alpha diversity\n",
    "    alpha_file = os.path.join(results_path, '11.Macrodiversity', 'Alpha_diversity_stats.tsv')\n",
    "    if os.path.exists(alpha_file):\n",
    "        results['alpha'] = pd.read_csv(alpha_file, sep='\\t', index_col=0)\n",
    "        print(f\"Loaded alpha diversity: {len(results['alpha'])} samples\")\n",
    "    \n",
    "    # Load gene microdiversity\n",
    "    gene_micro_file = os.path.join(results_path, '10.Microdiversity', 'global_gene_microdiversity.tsv')\n",
    "    if os.path.exists(gene_micro_file):\n",
    "        results['gene_micro'] = pd.read_csv(gene_micro_file, sep='\\t')\n",
    "        print(f\"Loaded gene microdiversity: {len(results['gene_micro'])} genes\")\n",
    "    \n",
    "    # Load abundance matrix\n",
    "    abundance_file = os.path.join(results_path, '11.Macrodiversity', 'normalized_abundances_table.tsv')\n",
    "    if os.path.exists(abundance_file):\n",
    "        results['abundance'] = pd.read_csv(abundance_file, sep='\\t', index_col=0)\n",
    "        print(f\"Loaded abundance matrix: {results['abundance'].shape}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "results = load_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display alpha diversity summary\n",
    "if results and 'alpha' in results:\n",
    "    print(\"Alpha Diversity Summary:\")\n",
    "    display(results['alpha'].describe())\n",
    "    \n",
    "    if PLOTLY_AVAILABLE:\n",
    "        # Interactive bar chart\n",
    "        fig = px.bar(results['alpha'].reset_index(), x='index', y='Richness',\n",
    "                    title='Species Richness by Sample',\n",
    "                    labels={'index': 'Sample', 'Richness': 'Species Richness'})\n",
    "        fig.show()\n",
    "    else:\n",
    "        # Static matplotlib plot\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        results['alpha']['Richness'].plot(kind='bar')\n",
    "        plt.title('Species Richness by Sample')\n",
    "        plt.ylabel('Richness')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display pN/pS distribution\n",
    "if results and 'gene_micro' in results:\n",
    "    pnps = results['gene_micro']['pNpS_ratio'].dropna()\n",
    "    pnps = pnps[~np.isinf(pnps) & (pnps < 10)]  # Filter outliers\n",
    "    \n",
    "    print(f\"pN/pS Statistics:\")\n",
    "    print(f\"  Mean: {pnps.mean():.3f}\")\n",
    "    print(f\"  Median: {pnps.median():.3f}\")\n",
    "    print(f\"  Genes with pN/pS < 1 (purifying): {(pnps < 1).sum()}\")\n",
    "    print(f\"  Genes with pN/pS > 1 (positive): {(pnps > 1).sum()}\")\n",
    "    \n",
    "    if PLOTLY_AVAILABLE:\n",
    "        fig = px.histogram(pnps, nbins=50, title='pN/pS Ratio Distribution',\n",
    "                          labels={'value': 'pN/pS Ratio', 'count': 'Gene Count'})\n",
    "        fig.add_vline(x=1, line_dash='dash', line_color='red',\n",
    "                     annotation_text='Neutral (pN/pS=1)')\n",
    "        fig.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.hist(pnps, bins=50, edgecolor='black')\n",
    "        plt.axvline(1, color='red', linestyle='--', label='Neutral')\n",
    "        plt.xlabel('pN/pS Ratio')\n",
    "        plt.ylabel('Gene Count')\n",
    "        plt.title('pN/pS Distribution')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Download Results\n\nDownload the results as a ZIP file."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "def download_results():\n",
    "    \"\"\"Create ZIP archive and download results.\"\"\"\n",
    "    results_path = os.path.join(output_dir.value, 'MetaPop')\n",
    "    \n",
    "    if not os.path.exists(results_path):\n",
    "        print(\"No results to download.\")\n",
    "        return\n",
    "    \n",
    "    zip_path = '/content/metapop_results'\n",
    "    shutil.make_archive(zip_path, 'zip', results_path)\n",
    "    \n",
    "    print(f\"Downloading {zip_path}.zip...\")\n",
    "    files.download(f'{zip_path}.zip')\n",
    "\n",
    "download_button = widgets.Button(\n",
    "    description='Download Results',\n",
    "    button_style='info',\n",
    "    tooltip='Download results as ZIP',\n",
    "    icon='download'\n",
    ")\n",
    "download_button.on_click(lambda b: download_results())\n",
    "\n",
    "display(download_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Need Help?\n",
    "\n",
    "- **Documentation**: See the MetaPop README for detailed usage instructions\n",
    "- **Issues**: Report bugs at https://github.com/espickle1/metapop/issues\n",
    "- **Contact**: James.Chang@bcm.edu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}