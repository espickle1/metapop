{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetaPop: Metagenomic Population Diversity Analysis\n",
    "\n",
    "This notebook provides an interactive interface for running MetaPop on Google Colab.\n",
    "\n",
    "**MetaPop** analyzes:\n",
    "- **Macrodiversity**: Sample-level diversity (richness, Shannon's H, Simpson, etc.)\n",
    "- **Microdiversity**: Within-population genetic variation (pi, theta, Tajima's D, pN/pS)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "Run this cell first to install all required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install system dependencies (samtools, bcftools, prodigal)\n",
    "!apt-get update -qq 2>/dev/null\n",
    "!apt-get install -y -qq samtools bcftools prodigal 2>/dev/null\n",
    "\n",
    "# Step 2: Install Python dependencies\n",
    "!pip install -q numpy pandas scipy pysam matplotlib seaborn scikit-learn plotly ipywidgets\n",
    "\n",
    "# Step 3: Clone and install MetaPop\n",
    "import os\n",
    "if not os.path.exists('metapop'):\n",
    "    !git clone https://github.com/espickle1/metapop.git\n",
    "\n",
    "%cd metapop\n",
    "!pip install -q .\n",
    "%cd ..\n",
    "\n",
    "print(\"Base dependencies and MetaPop installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 2. Mount Google Drive\n",
    "\n",
    "Mount your Google Drive to access data files and save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Your files will be available at /content/drive/MyDrive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Process BAM files from Google Drive to local Colab storage\nimport shutil\nimport os\n\n# Define paths\ndrive_bam_dir = '/content/drive/MyDrive/metapop_data/bams'  # Your Drive path\nlocal_bam_dir = '/content/local_bams'  # Local Colab storage\n\n# Create local directory\nos.makedirs(local_bam_dir, exist_ok=True)\n\n# Copy all BAM files to local storage\nprint(\"Copying BAM files to local storage (this may take a while)...\")\nfor f in os.listdir(drive_bam_dir):\n    if f.endswith('.bam') or f.endswith('.bai') or f.endswith('.bam.bai'):\n        src = os.path.join(drive_bam_dir, f)\n        dst = os.path.join(local_bam_dir, f)\n        if not os.path.exists(dst):\n            print(f\"  Copying {f}...\")\n            shutil.copy2(src, dst)\n        else:\n            print(f\"  {f} already exists locally\")\n\n# Index BAM files if index doesn't exist\nprint(\"\\nChecking/creating BAM indexes...\")\nfor f in os.listdir(local_bam_dir):\n    if f.endswith('.bam'):\n        bam_path = os.path.join(local_bam_dir, f)\n        bai_path = bam_path + '.bai'\n        alt_bai_path = bam_path[:-4] + '.bai'  # file.bai instead of file.bam.bai\n        if not os.path.exists(bai_path) and not os.path.exists(alt_bai_path):\n            print(f\"  Indexing {f}...\")\n            os.system(f'samtools index \"{bam_path}\"')\n        else:\n            print(f\"  {f} already indexed\")\n\nprint(f\"\\nDone! Use '{local_bam_dir}' as your BAM Directory in the widget above.\")\n\n# Verify BAM files are readable\nprint(\"\\nVerifying BAM files...\")\n!ls -la {local_bam_dir}/*.bam* | head -10"
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Validate BAM Files & References\n\nRun this cell to check for common issues **before** running MetaPop:\n1. **Integrity check** — verifies BAM files aren't corrupted\n2. **Re-indexing** — creates fresh `.bai` index files (eliminates stale index issues)\n3. **Header vs reference comparison** — checks that contig names in your BAM headers match your reference FASTAs\n\nIf you see **\"ZERO contig names match\"**, that means the BAM files were aligned against different reference sequences than the FASTAs you're providing. You'll need the exact reference used during alignment.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# === BAM File Validation & Diagnostics ===\n# This cell checks for common issues that cause MetaPop to produce empty results.\n\nimport os\nimport subprocess\n\n# --- Configuration ---\n# These should match the paths used in the cells above\nbam_dir = '/content/local_bams'\nref_dir = '/content/drive/MyDrive/metapop_data/references'\n\n# -------------------------------------------------------\n# 1. BAM INTEGRITY CHECK\n# -------------------------------------------------------\nprint(\"=\" * 60)\nprint(\"1. BAM INTEGRITY CHECK (samtools quickcheck)\")\nprint(\"=\" * 60)\n\nbam_files = sorted([f for f in os.listdir(bam_dir) if f.endswith('.bam')])\nprint(f\"Found {len(bam_files)} BAM file(s)\\n\")\n\nfor f in bam_files:\n    bam_path = os.path.join(bam_dir, f)\n    ret = subprocess.run(['samtools', 'quickcheck', bam_path],\n                         capture_output=True, text=True)\n    status = \"PASS\" if ret.returncode == 0 else \"FAIL\"\n    print(f\"  [{status}] {f}\")\n    if ret.returncode != 0:\n        print(f\"         Error: {ret.stderr.strip()}\")\n\n# -------------------------------------------------------\n# 2. RE-INDEX ALL BAM FILES (fresh .bai files)\n# -------------------------------------------------------\nprint(f\"\\n{'=' * 60}\")\nprint(\"2. RE-INDEXING ALL BAM FILES (fresh .bai files)\")\nprint(\"=\" * 60)\n\nfor f in bam_files:\n    bam_path = os.path.join(bam_dir, f)\n\n    # Remove old indexes\n    for idx_path in [bam_path + '.bai', bam_path.replace('.bam', '.bai')]:\n        if os.path.exists(idx_path):\n            os.remove(idx_path)\n\n    # Check if coordinate-sorted\n    ret = subprocess.run(['samtools', 'view', '-H', bam_path],\n                         capture_output=True, text=True)\n    if 'SO:coordinate' not in ret.stdout:\n        print(f\"  WARNING: {f} not coordinate-sorted — sorting now...\")\n        sorted_path = bam_path + '.sorting.tmp.bam'\n        subprocess.run(['samtools', 'sort', '-o', sorted_path, bam_path])\n        os.replace(sorted_path, bam_path)\n\n    # Create fresh index\n    ret = subprocess.run(['samtools', 'index', bam_path],\n                         capture_output=True, text=True)\n    if ret.returncode == 0:\n        print(f\"  Indexed: {f}\")\n    else:\n        print(f\"  FAILED:  {f} — {ret.stderr.strip()}\")\n\n# -------------------------------------------------------\n# 3. EXTRACT CONTIG NAMES FROM BAM HEADERS\n# -------------------------------------------------------\nprint(f\"\\n{'=' * 60}\")\nprint(\"3. BAM HEADER vs REFERENCE FASTA COMPARISON\")\nprint(\"=\" * 60)\n\nall_bam_contigs = set()\n\nfor f in bam_files:\n    bam_path = os.path.join(bam_dir, f)\n    ret = subprocess.run(['samtools', 'view', '-H', bam_path],\n                         capture_output=True, text=True)\n    contigs = set()\n    for line in ret.stdout.split('\\n'):\n        if line.startswith('@SQ'):\n            for part in line.split('\\t'):\n                if part.startswith('SN:'):\n                    contigs.add(part[3:])\n    all_bam_contigs.update(contigs)\n    print(f\"\\n  {f}: {len(contigs)} reference contig(s) in header\")\n    for c in sorted(contigs)[:5]:\n        print(f\"    - {c}\")\n    if len(contigs) > 5:\n        print(f\"    ... and {len(contigs) - 5} more\")\n\n# -------------------------------------------------------\n# 4. EXTRACT CONTIG NAMES FROM REFERENCE FASTAs\n# -------------------------------------------------------\nref_contigs = set()\n\nif os.path.exists(ref_dir):\n    ref_files = sorted([f for f in os.listdir(ref_dir)\n                        if f.endswith(('.fa', '.fasta', '.fna'))])\n    print(f\"\\nReference directory: {len(ref_files)} FASTA file(s)\")\n\n    for f in ref_files:\n        ref_path = os.path.join(ref_dir, f)\n        file_contigs = set()\n        with open(ref_path) as fh:\n            for line in fh:\n                if line.startswith('>'):\n                    # FASTA header — take just the first word (before any spaces)\n                    first_word = line[1:].strip().split()[0]\n                    file_contigs.add(first_word)\n        ref_contigs.update(file_contigs)\n        print(f\"  {f}: {len(file_contigs)} contig(s)\")\n        for c in sorted(file_contigs)[:3]:\n            print(f\"    - {c}\")\n        if len(file_contigs) > 3:\n            print(f\"    ... and {len(file_contigs) - 3} more\")\nelse:\n    print(f\"\\n  WARNING: Reference directory not found: {ref_dir}\")\n    print(f\"  Update 'ref_dir' at the top of this cell.\")\n\n# -------------------------------------------------------\n# 5. DIAGNOSIS\n# -------------------------------------------------------\nprint(f\"\\n{'=' * 60}\")\nprint(\"DIAGNOSIS\")\nprint(\"=\" * 60)\n\nif all_bam_contigs and ref_contigs:\n    overlap = all_bam_contigs & ref_contigs\n    only_in_bam = all_bam_contigs - ref_contigs\n    only_in_ref = ref_contigs - all_bam_contigs\n\n    print(f\"\\n  Unique contigs in BAM headers:  {len(all_bam_contigs)}\")\n    print(f\"  Unique contigs in references:   {len(ref_contigs)}\")\n    print(f\"  Matching contigs:               {len(overlap)}\")\n\n    if len(overlap) == 0:\n        print(\"\\n  *** PROBLEM: ZERO contig names match! ***\")\n        print(\"  This is why MetaPop produces empty results.\")\n        print(\"\\n  Example BAM contig names:\")\n        for c in sorted(all_bam_contigs)[:5]:\n            print(f\"    BAM: '{c}'\")\n        print(\"  Example reference contig names:\")\n        for c in sorted(ref_contigs)[:5]:\n            print(f\"    REF: '{c}'\")\n        print(\"\\n  The BAM files were aligned against different references\")\n        print(\"  than the FASTA files you are providing to MetaPop.\")\n        print(\"  You need the EXACT reference FASTA used during alignment.\")\n    elif len(overlap) < len(all_bam_contigs):\n        pct = 100 * len(overlap) / len(all_bam_contigs)\n        print(f\"\\n  Partial match: {pct:.1f}% of BAM contigs found in references\")\n        print(f\"  {len(only_in_bam)} BAM contig(s) NOT in references:\")\n        for c in sorted(only_in_bam)[:5]:\n            print(f\"    Missing: '{c}'\")\n    else:\n        print(\"\\n  All BAM contigs found in reference files!\")\n        print(\"  Header/reference mismatch is NOT the problem.\")\n        print(\"  Check MetaPop filter settings (coverage, depth thresholds).\")\nelif not all_bam_contigs:\n    print(\"\\n  No contigs found in BAM headers — files may be empty/unmapped.\")\nelif not ref_contigs:\n    print(\"\\n  No reference FASTAs found — cannot compare.\")\n\nprint(f\"\\n{'=' * 60}\")\nprint(\"VALIDATION COMPLETE\")\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Import Libraries and Initialize"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Try to import plotly for interactive plots\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    PLOTLY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n",
    "print(f\"Interactive plots (Plotly): {'Available' if PLOTLY_AVAILABLE else 'Not available'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Configure Pipeline Parameters\n\nUse the interactive widgets below to configure your analysis parameters."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path inputs with live validation and dark text\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Add CSS to make widget text darker and more readable\n",
    "display(HTML('''\n",
    "<style>\n",
    ".jupyter-widgets .widget-text input {\n",
    "    color: #000000 !important;\n",
    "    font-weight: 500;\n",
    "}\n",
    ".jupyter-widgets .widget-label {\n",
    "    color: #000000 !important;\n",
    "    font-weight: bold;\n",
    "}\n",
    ".jupyter-widgets .widget-inline-hbox .widget-label,\n",
    ".jupyter-widgets .widget-inline-vbox .widget-label {\n",
    "    color: #000000 !important;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "'''))\n",
    "\n",
    "print(\"=== File Paths ===\")\n",
    "print(\"Configure your input/output directories below.\")\n",
    "print()\n",
    "\n",
    "input_dir = widgets.Text(\n",
    "    value='/content/local_bams',\n",
    "    description='BAM Directory:',\n",
    "    style={'description_width': '150px', 'description_color': '#000000'},\n",
    "    layout=widgets.Layout(width='90%'),\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "reference = widgets.Text(\n",
    "    value='/content/drive/MyDrive/metapop_data/references',\n",
    "    description='Reference Directory:',\n",
    "    placeholder='Directory containing reference FASTA files',\n",
    "    style={'description_width': '150px', 'description_color': '#000000'},\n",
    "    layout=widgets.Layout(width='90%'),\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "genes = widgets.Text(\n",
    "    value='',\n",
    "    description='Genes File (optional):',\n",
    "    placeholder='Leave empty to auto-generate with Prodigal',\n",
    "    style={'description_width': '150px', 'description_color': '#000000'},\n",
    "    layout=widgets.Layout(width='90%'),\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "norm_file = widgets.Text(\n",
    "    value='',\n",
    "    description='Normalization File:',\n",
    "    placeholder='Leave empty to auto-generate from BAM read counts',\n",
    "    style={'description_width': '150px', 'description_color': '#000000'},\n",
    "    layout=widgets.Layout(width='90%'),\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "output_dir = widgets.Text(\n",
    "    value='/content/drive/MyDrive/metapop_results',\n",
    "    description='Output Directory:',\n",
    "    style={'description_width': '150px', 'description_color': '#000000'},\n",
    "    layout=widgets.Layout(width='90%'),\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "# Status indicator for path validation\n",
    "path_status = widgets.HTML(value='')\n",
    "\n",
    "def validate_paths(change=None):\n",
    "    \"\"\"Validate paths and update status.\"\"\"\n",
    "    status_parts = []\n",
    "    \n",
    "    # Check BAM directory\n",
    "    if os.path.exists(input_dir.value):\n",
    "        bam_files = [f for f in os.listdir(input_dir.value) if f.endswith('.bam')]\n",
    "        status_parts.append(f\"✅ BAM directory: {len(bam_files)} BAM file(s) found\")\n",
    "    else:\n",
    "        status_parts.append(f\"❌ BAM directory not found\")\n",
    "    \n",
    "    # Check reference directory\n",
    "    if os.path.exists(reference.value):\n",
    "        if os.path.isdir(reference.value):\n",
    "            ref_files = [f for f in os.listdir(reference.value) \n",
    "                        if f.endswith(('.fa', '.fasta', '.fna'))]\n",
    "            status_parts.append(f\"✅ Reference directory: {len(ref_files)} FASTA file(s) found\")\n",
    "        else:\n",
    "            status_parts.append(f\"⚠️ Reference is a file, not directory\")\n",
    "    else:\n",
    "        status_parts.append(f\"❌ Reference directory not found\")\n",
    "    \n",
    "    # Check output directory\n",
    "    if os.path.exists(output_dir.value):\n",
    "        status_parts.append(f\"✅ Output directory exists\")\n",
    "    else:\n",
    "        status_parts.append(f\"ℹ️ Output directory will be created\")\n",
    "    \n",
    "    path_status.value = '<br>'.join(status_parts)\n",
    "\n",
    "# Connect validation to path changes\n",
    "input_dir.observe(validate_paths, names='value')\n",
    "reference.observe(validate_paths, names='value')\n",
    "output_dir.observe(validate_paths, names='value')\n",
    "\n",
    "# Initial validation\n",
    "validate_paths()\n",
    "\n",
    "# Display widgets\n",
    "display(widgets.VBox([\n",
    "    input_dir,\n",
    "    reference, \n",
    "    genes,\n",
    "    norm_file,\n",
    "    output_dir,\n",
    "    widgets.HTML('<hr style=\"margin: 10px 0;\">'),\n",
    "    widgets.HTML('<b>Path Status:</b>'),\n",
    "    path_status\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter parameters with live value display and dark text\n",
    "print(\"=== Filter Parameters ===\")\n",
    "print(\"Adjust the sliders below. Values update in real-time.\")\n",
    "print()\n",
    "\n",
    "min_pct_id = widgets.FloatSlider(\n",
    "    value=95.0, min=80.0, max=100.0, step=0.5,\n",
    "    description='Min % Identity:',\n",
    "    style={'description_width': '150px', 'description_color': '#000000'},\n",
    "    layout=widgets.Layout(width='70%'),\n",
    "    readout=True,\n",
    "    readout_format='.1f',\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "min_length = widgets.IntSlider(\n",
    "    value=50, min=25, max=200, step=5,\n",
    "    description='Min Read Length:',\n",
    "    style={'description_width': '150px', 'description_color': '#000000'},\n",
    "    layout=widgets.Layout(width='70%'),\n",
    "    readout=True,\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "min_cov = widgets.IntSlider(\n",
    "    value=20, min=0, max=100, step=5,\n",
    "    description='Min Coverage (%):',\n",
    "    style={'description_width': '150px', 'description_color': '#000000'},\n",
    "    layout=widgets.Layout(width='70%'),\n",
    "    readout=True,\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "min_dep = widgets.IntSlider(\n",
    "    value=10, min=1, max=100, step=1,\n",
    "    description='Min Depth:',\n",
    "    style={'description_width': '150px', 'description_color': '#000000'},\n",
    "    layout=widgets.Layout(width='70%'),\n",
    "    readout=True,\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "truncation = widgets.FloatSlider(\n",
    "    value=10.0, min=0.0, max=49.0, step=1.0,\n",
    "    description='Truncation (%):',\n",
    "    style={'description_width': '150px', 'description_color': '#000000'},\n",
    "    layout=widgets.Layout(width='70%'),\n",
    "    readout=True,\n",
    "    readout_format='.1f',\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "# Live summary of filter settings\n",
    "filter_summary = widgets.HTML(value='')\n",
    "\n",
    "def update_filter_summary(change=None):\n",
    "    \"\"\"Update the filter summary display.\"\"\"\n",
    "    summary = f\"\"\"\n",
    "    <div style=\"background-color: #f0f0f0; padding: 10px; border-radius: 5px; margin-top: 10px; color: #000000;\">\n",
    "    <b>Current Filter Settings:</b><br>\n",
    "    • Reads must have ≥{min_pct_id.value:.1f}% identity to reference<br>\n",
    "    • Reads must be ≥{min_length.value} bp long<br>\n",
    "    • Contigs need ≥{min_cov.value}% coverage breadth<br>\n",
    "    • Positions need ≥{min_dep.value}x read depth<br>\n",
    "    • Truncate {truncation.value:.0f}% from each contig end\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    filter_summary.value = summary\n",
    "\n",
    "# Connect summary update to all sliders\n",
    "for slider in [min_pct_id, min_length, min_cov, min_dep, truncation]:\n",
    "    slider.observe(update_filter_summary, names='value')\n",
    "\n",
    "# Initial summary\n",
    "update_filter_summary()\n",
    "\n",
    "# Display with organized layout\n",
    "display(widgets.VBox([\n",
    "    min_pct_id,\n",
    "    min_length,\n",
    "    min_cov,\n",
    "    min_dep,\n",
    "    truncation,\n",
    "    filter_summary\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis options with live summary and dark text\n",
    "print(\"=== Analysis Options ===\")\n",
    "print(\"Select which analyses to run and configure threads.\")\n",
    "print()\n",
    "\n",
    "run_preproc = widgets.Checkbox(\n",
    "    value=True, \n",
    "    description='Run Preprocessing',\n",
    "    style={'description_width': 'initial', 'description_color': '#000000'},\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "run_microdiv = widgets.Checkbox(\n",
    "    value=True, \n",
    "    description='Run Microdiversity Analysis',\n",
    "    style={'description_width': 'initial', 'description_color': '#000000'},\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "run_macrodiv = widgets.Checkbox(\n",
    "    value=True, \n",
    "    description='Run Macrodiversity Analysis',\n",
    "    style={'description_width': 'initial', 'description_color': '#000000'},\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "run_viz = widgets.Checkbox(\n",
    "    value=True, \n",
    "    description='Generate Visualizations',\n",
    "    style={'description_width': 'initial', 'description_color': '#000000'},\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "threads = widgets.IntSlider(\n",
    "    value=4, min=1, max=16, step=1,\n",
    "    description='Threads:',\n",
    "    style={'description_width': '150px', 'description_color': '#000000'},\n",
    "    layout=widgets.Layout(width='50%'),\n",
    "    readout=True,\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "# Live summary of what will run\n",
    "analysis_summary = widgets.HTML(value='')\n",
    "\n",
    "def update_analysis_summary(change=None):\n",
    "    \"\"\"Update the analysis summary.\"\"\"\n",
    "    analyses = []\n",
    "    if run_preproc.value:\n",
    "        analyses.append(\"✅ Preprocessing (filter reads, compute coverage)\")\n",
    "    else:\n",
    "        analyses.append(\"⏭️ Skip preprocessing\")\n",
    "    \n",
    "    if run_microdiv.value:\n",
    "        analyses.append(\"✅ Microdiversity (SNPs, pi, theta, Tajima's D, pN/pS)\")\n",
    "    else:\n",
    "        analyses.append(\"⏭️ Skip microdiversity\")\n",
    "    \n",
    "    if run_macrodiv.value:\n",
    "        analyses.append(\"✅ Macrodiversity (richness, Shannon's H, beta diversity)\")\n",
    "    else:\n",
    "        analyses.append(\"⏭️ Skip macrodiversity\")\n",
    "    \n",
    "    if run_viz.value:\n",
    "        analyses.append(\"✅ Visualizations (plots and figures)\")\n",
    "    else:\n",
    "        analyses.append(\"⏭️ Skip visualizations\")\n",
    "    \n",
    "    summary = f\"\"\"\n",
    "    <div style=\"background-color: #e8f4e8; padding: 10px; border-radius: 5px; margin-top: 10px; color: #000000;\">\n",
    "    <b>Pipeline Configuration:</b><br>\n",
    "    {'<br>'.join(analyses)}<br>\n",
    "    <br>\n",
    "    <b>Using {threads.value} thread(s)</b> for parallel processing\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    analysis_summary.value = summary\n",
    "\n",
    "# Connect to all checkboxes and threads\n",
    "for widget in [run_preproc, run_microdiv, run_macrodiv, run_viz, threads]:\n",
    "    widget.observe(update_analysis_summary, names='value')\n",
    "\n",
    "# Initial summary\n",
    "update_analysis_summary()\n",
    "\n",
    "# Organize checkboxes in columns\n",
    "checkbox_box = widgets.HBox([\n",
    "    widgets.VBox([run_preproc, run_microdiv]),\n",
    "    widgets.VBox([run_macrodiv, run_viz])\n",
    "])\n",
    "\n",
    "display(widgets.VBox([\n",
    "    checkbox_box,\n",
    "    widgets.HTML('<br>'),\n",
    "    threads,\n",
    "    analysis_summary\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Run MetaPop Pipeline"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_metapop():\n",
    "    \"\"\"Run the MetaPop pipeline with configured parameters.\"\"\"\n",
    "    clear_output()\n",
    "    print(\"Starting MetaPop Pipeline...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Validate inputs\n",
    "    if not os.path.exists(input_dir.value):\n",
    "        print(f\"Error: BAM directory not found: {input_dir.value}\")\n",
    "        return\n",
    "    \n",
    "    # Handle reference path - MetaPop expects a directory\n",
    "    ref_path = reference.value\n",
    "    if os.path.isfile(ref_path):\n",
    "        print(f\"Warning: Reference path is a file, not a directory.\")\n",
    "        print(f\"File: {ref_path}\")\n",
    "        print(f\"MetaPop expects a directory containing FASTA files.\")\n",
    "        print(f\"Using parent directory: {os.path.dirname(ref_path)}\")\n",
    "        ref_path = os.path.dirname(ref_path)\n",
    "        print()\n",
    "    \n",
    "    if not os.path.exists(ref_path):\n",
    "        print(f\"Error: Reference directory not found: {ref_path}\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.isdir(ref_path):\n",
    "        print(f\"Error: Reference path is not a directory: {ref_path}\")\n",
    "        return\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir.value, exist_ok=True)\n",
    "    \n",
    "    # Build command\n",
    "    cmd = [\n",
    "        'metapop',\n",
    "        '--input_samples', input_dir.value,\n",
    "        '--reference', ref_path,\n",
    "        '--output', output_dir.value,\n",
    "        '--id_min', str(min_pct_id.value),\n",
    "        '--min_len', str(min_length.value),\n",
    "        '--min_cov', str(min_cov.value),\n",
    "        '--min_dep', str(min_dep.value),\n",
    "        '--trunc', str(truncation.value),\n",
    "        '--threads', str(threads.value),\n",
    "    ]\n",
    "    \n",
    "    if genes.value:\n",
    "        cmd.extend(['--genes', genes.value])\n",
    "    if norm_file.value:\n",
    "        cmd.extend(['--norm', norm_file.value])\n",
    "    if not run_microdiv.value:\n",
    "        cmd.append('--no_micro')\n",
    "    if not run_macrodiv.value:\n",
    "        cmd.append('--no_macro')\n",
    "    if not run_viz.value:\n",
    "        cmd.append('--no_viz')\n",
    "    \n",
    "    print(f\"Configuration:\")\n",
    "    print(f\"  Input: {input_dir.value}\")\n",
    "    print(f\"  Reference: {ref_path}\")\n",
    "    print(f\"  Output: {output_dir.value}\")\n",
    "    print(f\"  Threads: {threads.value}\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"\\nRunning MetaPop...\")\n",
    "    print()\n",
    "    \n",
    "    # Run the pipeline\n",
    "    try:\n",
    "        process = subprocess.Popen(\n",
    "            cmd,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            bufsize=1\n",
    "        )\n",
    "        \n",
    "        # Stream output in real-time\n",
    "        for line in process.stdout:\n",
    "            print(line, end='')\n",
    "        \n",
    "        process.wait()\n",
    "        \n",
    "        if process.returncode == 0:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"MetaPop pipeline completed successfully!\")\n",
    "            print(f\"Results saved to: {output_dir.value}\")\n",
    "        else:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(f\"MetaPop exited with error code: {process.returncode}\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(\"\\nError: MetaPop command not found.\")\n",
    "        print(\"Please make sure MetaPop is installed correctly.\")\n",
    "        print(\"Try running: !pip install -e /content/metapop\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during pipeline execution: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Create run button\n",
    "run_button = widgets.Button(\n",
    "    description='Run MetaPop',\n",
    "    button_style='success',\n",
    "    tooltip='Click to start the pipeline',\n",
    "    icon='play'\n",
    ")\n",
    "run_button.on_click(lambda b: run_metapop())\n",
    "\n",
    "display(run_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. View Results\n\nAfter the pipeline completes, use the cells below to explore results interactively."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results():\n",
    "    \"\"\"Load and display MetaPop results.\"\"\"\n",
    "    results_path = os.path.join(output_dir.value, 'MetaPop')\n",
    "    \n",
    "    if not os.path.exists(results_path):\n",
    "        print(f\"Results not found at: {results_path}\")\n",
    "        print(\"Please run the pipeline first.\")\n",
    "        return None\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Load alpha diversity\n",
    "    alpha_file = os.path.join(results_path, '11.Macrodiversity', 'Alpha_diversity_stats.tsv')\n",
    "    if os.path.exists(alpha_file):\n",
    "        results['alpha'] = pd.read_csv(alpha_file, sep='\\t', index_col=0)\n",
    "        print(f\"Loaded alpha diversity: {len(results['alpha'])} samples\")\n",
    "    \n",
    "    # Load gene microdiversity\n",
    "    gene_micro_file = os.path.join(results_path, '10.Microdiversity', 'global_gene_microdiversity.tsv')\n",
    "    if os.path.exists(gene_micro_file):\n",
    "        results['gene_micro'] = pd.read_csv(gene_micro_file, sep='\\t')\n",
    "        print(f\"Loaded gene microdiversity: {len(results['gene_micro'])} genes\")\n",
    "    \n",
    "    # Load abundance matrix\n",
    "    abundance_file = os.path.join(results_path, '11.Macrodiversity', 'normalized_abundances_table.tsv')\n",
    "    if os.path.exists(abundance_file):\n",
    "        results['abundance'] = pd.read_csv(abundance_file, sep='\\t', index_col=0)\n",
    "        print(f\"Loaded abundance matrix: {results['abundance'].shape}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "results = load_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display alpha diversity summary\n",
    "if results and 'alpha' in results:\n",
    "    print(\"Alpha Diversity Summary:\")\n",
    "    display(results['alpha'].describe())\n",
    "    \n",
    "    if PLOTLY_AVAILABLE:\n",
    "        # Interactive bar chart\n",
    "        fig = px.bar(results['alpha'].reset_index(), x='index', y='Richness',\n",
    "                    title='Species Richness by Sample',\n",
    "                    labels={'index': 'Sample', 'Richness': 'Species Richness'})\n",
    "        fig.show()\n",
    "    else:\n",
    "        # Static matplotlib plot\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        results['alpha']['Richness'].plot(kind='bar')\n",
    "        plt.title('Species Richness by Sample')\n",
    "        plt.ylabel('Richness')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display pN/pS distribution\n",
    "if results and 'gene_micro' in results:\n",
    "    pnps = results['gene_micro']['pNpS_ratio'].dropna()\n",
    "    pnps = pnps[~np.isinf(pnps) & (pnps < 10)]  # Filter outliers\n",
    "    \n",
    "    print(f\"pN/pS Statistics:\")\n",
    "    print(f\"  Mean: {pnps.mean():.3f}\")\n",
    "    print(f\"  Median: {pnps.median():.3f}\")\n",
    "    print(f\"  Genes with pN/pS < 1 (purifying): {(pnps < 1).sum()}\")\n",
    "    print(f\"  Genes with pN/pS > 1 (positive): {(pnps > 1).sum()}\")\n",
    "    \n",
    "    if PLOTLY_AVAILABLE:\n",
    "        fig = px.histogram(pnps, nbins=50, title='pN/pS Ratio Distribution',\n",
    "                          labels={'value': 'pN/pS Ratio', 'count': 'Gene Count'})\n",
    "        fig.add_vline(x=1, line_dash='dash', line_color='red',\n",
    "                     annotation_text='Neutral (pN/pS=1)')\n",
    "        fig.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.hist(pnps, bins=50, edgecolor='black')\n",
    "        plt.axvline(1, color='red', linestyle='--', label='Neutral')\n",
    "        plt.xlabel('pN/pS Ratio')\n",
    "        plt.ylabel('Gene Count')\n",
    "        plt.title('pN/pS Distribution')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Download Results\n\nDownload the results as a ZIP file."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "def download_results():\n",
    "    \"\"\"Create ZIP archive and download results.\"\"\"\n",
    "    results_path = os.path.join(output_dir.value, 'MetaPop')\n",
    "    \n",
    "    if not os.path.exists(results_path):\n",
    "        print(\"No results to download.\")\n",
    "        return\n",
    "    \n",
    "    zip_path = '/content/metapop_results'\n",
    "    shutil.make_archive(zip_path, 'zip', results_path)\n",
    "    \n",
    "    print(f\"Downloading {zip_path}.zip...\")\n",
    "    files.download(f'{zip_path}.zip')\n",
    "\n",
    "download_button = widgets.Button(\n",
    "    description='Download Results',\n",
    "    button_style='info',\n",
    "    tooltip='Download results as ZIP',\n",
    "    icon='download'\n",
    ")\n",
    "download_button.on_click(lambda b: download_results())\n",
    "\n",
    "display(download_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Need Help?\n",
    "\n",
    "- **Documentation**: See the MetaPop README for detailed usage instructions\n",
    "- **Issues**: Report bugs at https://github.com/espickle1/metapop/issues\n",
    "- **Contact**: James.Chang@bcm.edu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}